{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "TRAINING_SET_DIR = os.getcwd() + '/drive/MyDrive/dog_pics/all_breeds_augmented/training_set_2/'\n",
    "VALIDATION_SET_DIR = os.getcwd() + '/drive/MyDrive/dog_pics/all_breeds_augmented/validation_set/'\n",
    "\n",
    "IMAGE_WIDTH = 500\n",
    "IMAGE_HEIGHT = 375\n",
    "dog_pics_training = 188\n",
    "dog_pics_validation = 50\n",
    "\n",
    "def run_model():\n",
    "    # Use InceptionV3 model for feature extraction\n",
    "    inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "    inception_output = inception.output\n",
    "    inception_output = GlobalAveragePooling2D()(inception_output)\n",
    "\n",
    "    # Add fully connected layer and output (prediction/classification) layer\n",
    "    fc_layer = Dense(units=480, activation ='relu')(inception_output)\n",
    "    predictions = Dense(120, activation ='softmax')(fc_layer)\n",
    "    model = Model(inputs = inception.input, outputs = predictions)\n",
    "\n",
    "    # Freeze InceptionV3 layers\n",
    "    for layer in inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Summarise and compile model\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Generate training and validation data with augmentations\n",
    "    gen_training = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=360)\n",
    "    training_data = gen_training.flow_from_directory(\n",
    "        directory=TRAINING_SET_DIR,\n",
    "        target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "        class_mode='categorical',\n",
    "    )\n",
    "\n",
    "    gen_validation = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=360)\n",
    "    validating_data = gen_validation.flow_from_directory(\n",
    "        directory=VALIDATION_SET_DIR,\n",
    "        target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "        class_mode='categorical',\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    model.fit_generator(\n",
    "        training_data,\n",
    "        steps_per_epoch=training_data.n // training_data.batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validating_data,\n",
    "        validation_steps=validating_data.n // validating_data.batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "    # Visualizing layers to see which to freeze. (Winging it with keras tutorial)\n",
    "    for i, layer in enumerate(inception.layers):\n",
    "      print(i, layer.name)\n",
    "\n",
    "    # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "    # the first 249 layers and unfreeze the rest:\n",
    "    for layer in model.layers[:249]:\n",
    "      layer.trainable = False\n",
    "    for layer in model.layers[249:]:\n",
    "      layer.trainable = True\n",
    "\n",
    "    # we need to recompile the model for these modifications to take effect\n",
    "    # we use SGD with a low learning rate\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(\n",
    "        training_data,\n",
    "        steps_per_epoch=training_data.n // training_data.batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=validating_data,\n",
    "        validation_steps=validating_data.n // validating_data.batch_size\n",
    "    )\n"
   ]
  }
 ]
}